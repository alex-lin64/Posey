{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 33 keypoints are in order\n",
    "\n",
    "0 - nose \\\n",
    "1 - left eye (inner) \\\n",
    "2 - left eye \\\n",
    "3 - left eye (outer) \\\n",
    "4 - right eye (inner) \\\n",
    "5 - right eye \\\n",
    "6 - right eye (outer) \\\n",
    "7 - left ear \\\n",
    "8 - right ear \\\n",
    "9 - mouth (left) \\\n",
    "10 - mouth (right) \\\n",
    "11 - left shoulder \\\n",
    "12 - right shoulder \\\n",
    "13 - left elbow \\\n",
    "14 - right elbow \\\n",
    "15 - left wrist \\\n",
    "16 - right wrist \\\n",
    "17 - left pinky \\\n",
    "18 - right pinky \\\n",
    "19 - left index \\\n",
    "20 - right index \\\n",
    "21 - left thumb \\\n",
    "22 - right thumb \\\n",
    "23 - left hip \\\n",
    "24 - right hip \\\n",
    "25 - left knee \\\n",
    "26 - right knee \\\n",
    "27 - left ankle \\\n",
    "28 - right ankle \\\n",
    "29 - left heel \\\n",
    "30 - right heel \\\n",
    "31 - left foot index \\\n",
    "32 - right foot index \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For squat detection, we don't need to the keypoints 1, 3, 4, and 5 (too much info about eyes), \\\n",
    "9 and 10 (don't need to know mouth position), and 17-22 (info about fingers too detailed, only \\\n",
    "need wrist keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture Keypoints to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_pose(keypoints, filepath, classification):\n",
    "    \"\"\"\n",
    "    Cleans keypoints data, writes file to csv.  \n",
    "\n",
    "    :params:\n",
    "        - keypoints: landmark obj of all 33 keypoints w/ x, y, z, and visibility\n",
    "        - filepath: path of csv file to write to\n",
    "        - classification: 1 if up position, 0 if down position\n",
    "    \"\"\"\n",
    "    # clean up unwanted keypoints\n",
    "    keypoints = keypoints[:1] + keypoints[2:3] + keypoints[6:9] + keypoints[11:17] + keypoints[23:33]\n",
    "    # flatten to 1d vector\n",
    "    cleaned_kp = np.array([[x.x, x.y, x.z] for x in keypoints], dtype=\"float32\").flatten() \n",
    "    cleaned_kp = np.append(cleaned_kp, classification)\n",
    "    cleaned_kp = cleaned_kp.reshape(1, len(cleaned_kp))\n",
    "    df = pd.DataFrame(cleaned_kp)\n",
    "\n",
    "    # write data to cvs\n",
    "    file_exists = os.path.isfile(filepath)\n",
    "    if not file_exists:\n",
    "        df.to_csv(filepath, index=False)\n",
    "    else:\n",
    "        df.to_csv(filepath, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# starts video capture on video\n",
    "cap = cv2.VideoCapture('data\\\\test_videos\\\\Barbell Back Squat - Front View.mp4')\n",
    "csv_filepath = \"data\\\\squat_data.csv\"\n",
    "\n",
    "# runs mediapipe pose detection\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # changing display colors\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame.flags.writeable = False\n",
    "        results = pose.process(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            results.pose_landmarks, \n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"Webcam Feed\", frame)\n",
    "\n",
    "        k = cv2.waitKey(1)\n",
    "        if k == ord('u'):\n",
    "            # captures keypoints for up position\n",
    "            capture_pose(results.pose_landmarks.landmark, csv_filepath, 1)\n",
    "        elif k == ord('d'):\n",
    "            # captures keypoints for down position\n",
    "            capture_pose(results.pose_landmarks.landmark, csv_filepath, 0)\n",
    "        elif k == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
